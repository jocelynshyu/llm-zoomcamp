{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6589ed7-2a77-4d2e-b0d2-69654dfaa64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "embedding_vector = embedding_model.encode(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a88bf6-3552-43d7-a7ff-ad7ee391c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078222655"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2612a-8ea4-441d-b2b2-39e7942eeda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696d80cc-d6e2-4ce7-8651-c0470f1d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6572afe5-de01-452c-8da3-1f74db1af35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filterCourse(q):\n",
    "    return q['course'] == 'machine-learning-zoomcamp'\n",
    "\n",
    "filtered_documents = list(filter(filterCourse, documents))\n",
    "len(filtered_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c87bdc1-2861-4557-b49e-b1bee7856587",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for document in filtered_documents:\n",
    "    qa_text = f\"{document['question']} {document['text']}\"\n",
    "    embedding = embedding_model.encode(qa_text)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a185fe9-6004-4584-8880-3432ccd7bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 768)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(embeddings)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07767c45-a4e3-44c7-b6e3-861ca0f47ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "075c643c-4bed-4bab-9ed0-1dadf1405dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X.dot(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9e60484-45f4-4b47-9ea6-6b1ae4dd085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506573"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999890b1-9c9a-4bd4-a25b-18325e61fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b53c05-1059-43ea-b538-4d9157bfc971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You can find the latest and up-to-date deadlines here: https://docs.google.com/spreadsheets/d/e/2PACX-1vQACMLuutV5rvXg5qICuJGL-yZqIV0FBD84CxPdC5eZHf8TfzB-CJT_3Mo7U7oGVTXmSihPgQxuuoku/pubhtml\\nAlso, take note of Announcements from @Au-Tomator for any extensions or other news. Or, the form may also show the updated deadline, if Instructor(s) has updated it.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - What are homework and project deadlines?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'a1daf537'},\n",
       " {'text': 'After you submit your homework it will be graded based on the amount of questions in a particular homework. You can see how many points you have right on the page of the homework up top. Additionally in the leaderboard you will find the sum of all points you’ve earned - points for Homeworks, FAQs and Learning in Public. If homework is clear, others work as follows: if you submit something to FAQ, you get one point, for each learning in a public link you get one point.\\n(https://datatalks-club.slack.com/archives/C01FABYF2RG/p1706846846359379?thread_ts=1706825019.546229&cid=C01FABYF2RG)',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework and Leaderboard - what is the system for points in the course management platform?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '29865466'},\n",
       " {'text': \"There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\\nData-Engineering (Jan - Apr)\\nMLOps (May - Aug)\\nMachine Learning (Sep - Jan)\\nThere's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\\nThey follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - how many Zoomcamps in a year?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '2ed9b986'},\n",
       " {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '70ac8e80'},\n",
       " {'text': 'You can set it up on your laptop or PC if you prefer to work locally from your laptop or PC.\\nYou might face some challenges, especially for Windows users. If you face cnd2\\nIf you prefer to work on the local machine, you may start with the week 1 Introduction to Docker and follow through.\\nHowever, if you prefer to set up a virtual machine, you may start with these first:\\nUsing GitHub Codespaces\\nSetting up the environment on a cloudV Mcodespace\\nI decided to work on a virtual machine because I have different laptops & PCs for my home & office, so I can work on this boot camp virtually anywhere.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Should I use my local machine, GCP, or GitHub Codespaces for my environment?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ddf6c1b3'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "search_engine = VectorSearchEngine(documents=documents, embeddings=X)\n",
    "search_engine.search(embedding_vector, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3196060f-4f18-4244-a2a3-887d11e80f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "421a8a50-162c-45ec-b494-f962b832426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ace948e2-58b1-44cd-bcfd-6b6b8902baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Where can I sign up for the course?', 'course': 'machine-learning-zoomcamp', 'document': '0227b872'}\n"
     ]
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "print(record)\n",
    "\n",
    "query = record['question']\n",
    "document_id = record['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "851d5e49-ae76-471d-858e-71ee586475b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_query = embedding_model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04ad76fc-cd1e-433c-92f3-3f16c057559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_engine.search(v_query, num_results=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db6d6ba9-b711-40af-aed9-1cc6bf9d7eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"✅SOLUTION: pip install confluent-kafka[avro].\\nFor some reason, Conda also doesn't include this when installing confluent-kafka via pip.\\nMore sources on Anaconda and confluent-kafka issues:\\nhttps://github.com/confluentinc/confluent-kafka-python/issues/590\\nhttps://github.com/confluentinc/confluent-kafka-python/issues/1221\\nhttps://stackoverflow.com/questions/69085157/cannot-import-producer-from-confluent-kafka\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': \"ModuleNotFoundError: No module named 'avro'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '1edd4630'},\n",
       " {'text': 'GitHub Codespaces offers you computing Linux resources with many pre-installed tools (Docker, Docker Compose, Python).\\nYou can also open any GitHub repository in a GitHub Codespace.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Is GitHub codespaces an alternative to using cli/git bash to ingest the data and create a docker file?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ac25d3af'},\n",
       " {'text': 'Even after we have exported our paths correctly you may find that  even though Jupyter is installed you might not have Jupyter Noteboopgak for one reason or another. Full instructions are found here (for my walkthrough) or here (where I got the original instructions from) but are included below. These instructions include setting up a virtual environment (handy if you are on your own machine doing this and not a VM):\\nFull steps:\\nUpdate and upgrade packages:\\nsudo apt update && sudo apt -y upgrade\\nInstall Python:\\nsudo apt install python3-pip python3-dev\\nInstall Python virtualenv:\\nsudo -H pip3 install --upgrade pip\\nsudo -H pip3 install virtualenv\\nCreate a Python Virtual Environment:\\nmkdir notebook\\ncd notebook\\nvirtualenv jupyterenv\\nsource jupyterenv/bin/activate\\nInstall Jupyter Notebook:\\npip install jupyter\\nRun Jupyter Notebook:\\njupyter notebook',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Exception: Jupyter command `jupyter-notebook` not found.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'd970a0da'},\n",
       " {'text': 'You need to create the Hadoop /bin directory manually and add the downloaded files in there, since the shell script provided for Windows installation just puts them in /c/tools/hadoop-3.2.0/ .',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Hadoop - FileNotFoundException: Hadoop bin directory does not exist , when trying to write (Windows)',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'ce508f3c'},\n",
       " {'text': \"When submit a job, it might throw an error about Java in log panel within Dataproc. I changed the Versioning Control when I created a cluster, so it means that I delete the cluster and created a new one, and instead of choosing Debian-Hadoop-Spark, I switch to Ubuntu 20.02-Hadoop3.3-Spark3.3 for Versioning Control feature, the main reason to choose this is because I have the same Ubuntu version in mi laptop, I tried to find documentation to sustent this but unfortunately I couldn't nevertheless it works for me.\",\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'py4j.protocol.Py4JJavaError  GCP',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '6b26d73c'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "536f383b-0cad-4a94-b8bb-88d1820e7402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_id: c6a22665\n",
      "result[id]: 1edd4630\n",
      "document_id: c6a22665\n",
      "result[id]: ac25d3af\n",
      "document_id: c6a22665\n",
      "result[id]: d970a0da\n",
      "document_id: c6a22665\n",
      "result[id]: ce508f3c\n",
      "document_id: c6a22665\n",
      "result[id]: 6b26d73c\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print('document_id: ' + document_id)\n",
    "    print('result[id]: ' + result['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e11fe4-5cc2-4c25-9b22-97dbefe44468",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37342a14-c673-4360-b812-151d163ed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0\n",
    "for record in ground_truth:\n",
    "    query = record['question']\n",
    "    document_id = record['document']\n",
    "    v_query = embedding_model.encode(query)\n",
    "    results = search_engine.search(v_query, num_results=5)\n",
    "    for result in results:\n",
    "        if document_id in result['id']:\n",
    "            hits += 1\n",
    "            break\n",
    "\n",
    "hitrate = hits / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87473145-8673-4cfa-be30-8dd3fcafe822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8766f0d-a0cc-485f-ad19-dfbec3f38208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6df71b-e75d-406e-8441-d67770ac7c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
